import os
import pandas as pd

# Change this to your target folder
folder_path = "path/to/your/folder"
output_file = "merged_output.csv"

# Define chunk size based on your system's memory
chunk_size = 100_000  

# Get all CSV files in the folder
csv_files = [f for f in os.listdir(folder_path) if f.endswith(".csv")]

print(f"Found {len(csv_files)} CSV files to merge.")

# Open the output file in write mode to store the merged data
with open(output_file, "w", encoding="utf-8", newline="") as out_file:
    first_file = True  # Track the first file for writing headers

    for file in csv_files:
        file_path = os.path.join(folder_path, file)
        total_rows = 0  # Track the number of rows in each file
        
        print(f"Processing: {file}")

        for chunk in pd.read_csv(file_path, chunksize=chunk_size):
            chunk["filename"] = file  # Add filename as a column
            total_rows += len(chunk)

            # Write header only for the first file
            chunk.to_csv(out_file, mode="a", index=False, header=first_file)
            first_file = False  # Ensure headers are not repeated
        
        print(f"  -> {file}: {total_rows} rows processed.")

print("Merging complete. Output saved to:", output_file)