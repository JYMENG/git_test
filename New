import sqlite3
import pandas as pd

# Step 1: Create an in-memory SQLite database
conn = sqlite3.connect(':memory:')
cursor = conn.cursor()

# Step 2: Read the CSV in chunks and load into a temporary table
chunk_size = 10000
for chunk in pd.read_csv('your_large_file.csv', dtype=str, chunksize=chunk_size):
    chunk.to_sql('data', conn, if_exists='replace', index=False)  # 'replace' ensures it's overwritten in each chunk

# Step 3: Calculate max values for each key
cursor.execute('''
    CREATE TEMPORARY VIEW max_values AS
    SELECT
        key,
        MAX(datetime_column) AS max_datetime,
        MAX(column1) AS max_column1,
        MAX(column2) AS max_column2
    FROM data
    GROUP BY key
''')

# Step 4: Filter the results by date range
start_date = '2023-01-01'
end_date = '2023-12-31'

cursor.execute('''
    CREATE TEMPORARY VIEW filtered_max_values AS
    SELECT *
    FROM max_values
    WHERE max_datetime BETWEEN ? AND ?
''', (start_date, end_date))

# Step 5: Perform the inner join with the original data
cursor.execute('''
    SELECT d.key, d.datetime_column, d.column1, d.column2, fm.max_datetime, fm.max_column1, fm.max_column2
    FROM data d
    INNER JOIN filtered_max_values fm
    ON d.key = fm.key AND d.datetime_column = fm.max_datetime
''')

# Step 6: Fetch the result and write it to a CSV file
result = cursor.fetchall()

# Convert the result to a pandas DataFrame
columns = ['key', 'datetime_column', 'column1', 'column2', 'max_datetime', 'max_column1', 'max_column2']
df_result = pd.DataFrame(result, columns=columns)

# Write the DataFrame to a CSV file
df_result.to_csv('filtered_output.csv', index=False)

# Close the connection
conn.close()

print("Process complete. The result is saved in 'filtered_output.csv'.")