from pathlib import Path
import re

def line_starts_with_rownum(line: str, delimiter: str = ",") -> bool:
    # look at the first token before the first delimiter
    first = line.split(delimiter, 1)[0].strip().strip('"').strip("'")
    return first.isdigit()

def fix_broken_rows_in_folder(
    input_folder: str,
    output_file: str,
    delimiter: str = ",",
    enc="utf-8-sig",
    expected_cols: int | None = None,   # e.g., 12; leave None to skip this check
    add_source_col: bool = False        # prepend source filename if True
):
    folder = Path(input_folder)
    files = sorted(
        list(folder.glob("*.csv")) + 
        list(folder.glob("*.txt")) + 
        list(folder.glob("*.htm")) + 
        list(folder.glob("*.html"))
    )
    if not files:
        raise FileNotFoundError(f"No matching files in {folder}")

    log_path = Path(output_file).with_suffix(".repair.log")
    anomalies = []

    def flush_record(buf: list[str]) -> str:
        # Join all physical lines of the current record into one logical line
        # Use a space to avoid accidental token run-on
        return " ".join(s.strip() for s in buf if s.strip())

    with open(output_file, "w", encoding=enc, newline="") as fout:
        for f in files:
            with open(f, "r", encoding=enc, errors="replace") as fin:
                current_buf = []  # collects physical lines for one logical record
                for raw in fin:
                    line = raw.rstrip("\n\r")
                    if not line.strip():
                        # blank line → treat as continuation separator if inside a record
                        if current_buf:
                            current_buf.append("")  # keep a space gap later
                        continue

                    if line_starts_with_rownum(line, delimiter):
                        # New record boundary
                        if current_buf:
                            logical = flush_record(current_buf)
                            # optional sanity check on column count
                            if expected_cols is not None:
                                cols = logical.split(delimiter)
                                if len(cols) != expected_cols:
                                    anomalies.append(
                                        f"{f.name}: rownum={cols[0] if cols else '?'} "
                                        f"cols={len(cols)} expected={expected_cols} :: {logical[:200]}"
                                    )
                            if add_source_col:
                                fout.write(f"{f.name}{delimiter}{logical}\n")
                            else:
                                fout.write(logical + "\n")
                            current_buf.clear()
                        # start new record
                        current_buf.append(line)
                    else:
                        # continuation of the current record
                        if not current_buf:
                            # orphan continuation; log and start a pseudo-record
                            anomalies.append(f"{f.name}: orphan continuation → {line[:200]}")
                            current_buf.append(line)
                        else:
                            current_buf.append(line)

                # flush last buffered record for this file
                if current_buf:
                    logical = flush_record(current_buf)
                    if expected_cols is not None:
                        cols = logical.split(delimiter)
                        if len(cols) != expected_cols:
                            anomalies.append(
                                f"{f.name}: rownum={cols[0] if cols else '?'} "
                                f"cols={len(cols)} expected={expected_cols} :: {logical[:200]}"
                            )
                    if add_source_col:
                        fout.write(f"{f.name}{delimiter}{logical}\n")
                    else:
                        fout.write(logical + "\n")

    # write anomalies log
    if anomalies:
        with open(log_path, "w", encoding=enc) as lg:
            lg.write("\n".join(anomalies))
        print(f"Done. Corrected output → {output_file}\nAnomalies logged → {log_path}")
    else:
        print(f"Done. Corrected output → {output_file} (no anomalies)")

# Example:
# fix_broken_rows_in_folder(
#     input_folder=r"C:\path\to\folder",
#     output_file=r"C:\path\to\corrected.csv",
#     delimiter=",",
#     expected_cols=None,     # set an integer if you know the correct column count
#     add_source_col=False
# )