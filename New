import pandas as pd

# Input file path
input_file = "your_file.csv"
output_file = "output_file.csv"

# Load the file into a pandas DataFrame
df = pd.read_csv(input_file)

# Sort by key (ID and Sub ID) and datetime column
df.sort_values(by=['ID', 'Sub ID', 'datetime_column'], inplace=True)

# Define the columns to check for duplicates
columns_to_check = ['ID', 'Sub ID', 'datetime_column']

# Drop duplicate rows based on the defined columns, keeping the first occurrence
df = df.drop_duplicates(subset=columns_to_check, keep='first')

# Save the result to a new file
df.to_csv(output_file, index=False)

print(f"Processed file saved to: {output_file}")