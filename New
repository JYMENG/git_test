import os

# Root directory and output file
root_dir = '/path/to/your/folder'
output_file = 'combined_output.csv'

# Collect all HTML/HTM files, sorted by descending subfolder
html_files = []
for dirpath, _, filenames in os.walk(root_dir):
    for fname in filenames:
        if fname.lower().endswith(('.htm', '.html')):
            html_files.append(os.path.join(dirpath, fname))
html_files = sorted(html_files, key=lambda x: os.path.dirname(x), reverse=True)

seen_content = set()
header = None
rows_to_write = []

for file_path in html_files:
    with open(file_path, 'r', encoding='utf-8', errors='ignore') as in_f:
        for line_no, line in enumerate(in_f):
            line = line.strip()
            if not line:
                continue

            parts = line.split(',')
            if len(parts) < 2:
                continue  # not enough data after dropping index

            # Drop index column
            data_parts = parts[1:]
            line_core = ','.join(data_parts)

            # Handle header logic
            if line_no == 0:
                if header is None:
                    header = data_parts  # keep only first file's header
                continue
            elif header is not None and data_parts == header:
                continue  # skip duplicate header in later files

            # Deduplicate based on content only
            if line_core not in seen_content:
                seen_content.add(line_core)
                rows_to_write.append((line_core, file_path))

# Write output file
with open(output_file, 'w', encoding='utf-8') as out_f:
    if header:
        out_f.write(','.join(header) + ',source_file\n')
    for core_line, src in rows_to_write:
        out_f.write(f"{core_line},{src}\n")

print(f"\nâœ… Combined CSV written to: {output_file}")
print(f"ðŸ§¾ Rows written: {len(rows_to_write)}")