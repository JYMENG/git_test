import os
import pandas as pd

def process_files_in_folder(folder_path):
    """
    Processes all files in a given folder.

    1. Reads each CSV file.
    2. Extracts unique IDs based on two date columns within a specified time period.
    3. Retrieves all unique records associated with the extracted IDs.

    Args:
        folder_path: Path to the folder containing the CSV files.

    Returns:
        A list of DataFrames, one for each processed file.
    """

    file_list = [f for f in os.listdir(folder_path) if f.endswith('.csv')]
    all_dataframes = []

    for file_name in file_list:
        file_path = os.path.join(folder_path, file_name)
        try:
            df = pd.read_csv(file_path)

            # Define the time period (example: last 30 days)
            end_date = pd.to_datetime('today')
            start_date = end_date - pd.DateOffset(days=30)

            # Convert date columns to datetime objects
            df['date_column1'] = pd.to_datetime(df['date_column1'])
            df['date_column2'] = pd.to_datetime(df['date_column2'])

            # Filter data within the time period
            df_filtered = df[(df['date_column1'] >= start_date) & (df['date_column1'] <= end_date) | 
                           (df['date_column2'] >= start_date) & (df['date_column2'] <= end_date)]

            # Get unique IDs
            unique_ids = df_filtered['id'].unique()

            # Get all records with unique IDs
            df_unique = df[df['id'].isin(unique_ids)]

            all_dataframes.append(df_unique)

        except Exception as e:
            print(f"Error processing {file_name}: {e}")

    return all_dataframes

# Example usage
folder_path = "/path/to/your/folder"  # Replace with the actual folder path
processed_dataframes = process_files_in_folder(folder_path)

# Further processing or analysis can be performed on the processed_dataframes 
