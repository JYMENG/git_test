import csv
from datetime import datetime, timedelta

def process_huge_file(file_path, date_column1_index, date_column2_index, id_index, time_period_days=30):
    """
    Processes a large file without using pandas.

    Args:
        file_path: Path to the file.
        date_column1_index: Index of the first date column in the file.
        date_column2_index: Index of the second date column in the file.
        id_index: Index of the ID column in the file.
        time_period_days: Number of days for the time period.

    Yields:
        A list of rows that match the criteria.
    """

    end_date = datetime.now()
    start_date = end_date - timedelta(days=time_period_days)

    with open(file_path, 'r') as file:
        reader = csv.reader(file)
        header = next(reader)  # Read the header row

        for row in reader:
            try:
                date1_str = row[date_column1_index]
                date2_str = row[date_column2_index]
                date1 = datetime.strptime(date1_str, '%Y-%m-%d')  # Adjust format as needed
                date2 = datetime.strptime(date2_str, '%Y-%m-%d')  # Adjust format as needed

                if (start_date <= date1 <= end_date) or (start_date <= date2 <= end_date):
                    yield row

            except (ValueError, IndexError):
                # Handle potential errors (e.g., invalid date format, missing columns)
                print(f"Error processing row: {row}")

def get_unique_ids(file_path, id_index):
    """
    Gets unique IDs from the file without using pandas.

    Args:
        file_path: Path to the file.
        id_index: Index of the ID column in the file.

    Returns:
        A set of unique IDs.
    """

    unique_ids = set()
    with open(file_path, 'r') as file:
        reader = csv.reader(file)
        next(reader)  # Skip header

        for row in reader:
            try:
                unique_ids.add(row[id_index])
            except IndexError:
                pass  # Handle missing ID column

    return unique_ids

# Example usage
file_path = "/path/to/your/file.csv"
date_column1_index = 0
date_column2_index = 1
id_index = 2

# Get unique IDs
unique_ids = get_unique_ids(file_path, id_index)

# Process the file and filter based on unique IDs
with open(file_path, 'r') as file:
    reader = csv.reader(file)
    header = next(reader)  # Read the header row

    for row in reader:
        if row[id_index] in unique_ids:
            # Process the row (e.g., write to a new file, perform calculations)
            print(row) 
