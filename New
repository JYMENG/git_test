import os

# Root folder path
root_dir = '/path/to/your/folder'
output_file = 'combined_output.csv'

# Collect all HTML files, sorted by descending folder path
html_files = []
for dirpath, _, filenames in os.walk(root_dir):
    for fname in filenames:
        if fname.lower().endswith(('.htm', '.html')):
            html_files.append(os.path.join(dirpath, fname))
html_files = sorted(html_files, key=lambda x: os.path.dirname(x), reverse=True)

seen_content = set()
header = None
rows_to_write = []

for file_path in html_files:
    with open(file_path, 'r', encoding='utf-8', errors='ignore') as in_f:
        for line_no, line in enumerate(in_f):
            line = line.strip()
            if not line:
                continue

            parts = line.split(',')
            if len(parts) < 2:
                continue  # not a valid data line

            # Remove index column
            data_parts = parts[1:]
            line_core = ','.join(data_parts)

            # Handle header
            if line_no == 0:
                if not header:
                    header = data_parts  # store header only from first file
                continue
            elif line_core == ','.join(header):
                continue  # skip duplicate headers

            # Deduplicate based on content only (excluding file path)
            if line_core not in seen_content:
                seen_content.add(line_core)
                rows_to_write.append((line_core, file_path))

# Write output
with open(output_file, 'w', encoding='utf-8') as out_f:
    out_f.write(','.join(header) + ',source_file\n')
    for core_line, src in rows_to_write:
        out_f.write(f"{core_line},{src}\n")

print(f"\nâœ… Combined CSV written to: {output_file}. Total rows: {len(rows_to_write)}")