import sqlite3
import openpyxl
import os
import warnings

# Suppress openpyxl style warnings
warnings.filterwarnings("ignore", category=UserWarning, module="openpyxl")

# Paths to your folders and user ID file
folder1_path = "path/to/folder1"
folder2_path = "path/to/folder2"
user_id_file = "path/to/user_ids.xlsx"

# Connect to a file-based SQLite database
db_file = "large_data.db"
if os.path.exists(db_file):
    os.remove(db_file)  # Clean start
conn = sqlite3.connect(db_file)
cursor = conn.cursor()

# Function to create table dynamically based on first sheet headers
def create_table_from_headers(file_path, table_name):
    try:
        wb = openpyxl.load_workbook(file_path, read_only=True)
        first_sheet = wb.sheetnames[0]
        sheet = wb[first_sheet]
        # Get headers from first row, include all cells (even empty ones) based on max_column
        headers = []
        first_row = next(sheet.rows)
        for i, cell in enumerate(first_row):
            header = cell.value if cell.value is not None else f"column_{i+1}"
            headers.append(str(header))
        wb.close()
        
        if not headers:
            print(f"Warning: No headers found in {file_path} for {table_name}")
            return None
        
        print(f"Creating {table_name} with headers: {headers}")
        columns = ", ".join([f'"{h}" TEXT' for h in headers])
        cursor.execute(f"CREATE TABLE IF NOT EXISTS {table_name} ({columns})")
        return headers
    except Exception as e:
        print(f"Error creating table from {file_path}: {e}")
        return None

# Function to process a folder and insert rows incrementally
def process_folder(folder_path, table_name):
    headers = None
    rows_inserted = 0
    for filename in os.listdir(folder_path):
        if filename.endswith(".xlsx"):
            file_path = os.path.join(folder_path, filename)
            try:
                wb = openpyxl.load_workbook(file_path, read_only=True)
                
                # Set headers from first sheet of first file
                if not headers:
                    headers = create_table_from_headers(file_path, table_name)
                    if not headers:
                        wb.close()
                        continue
                
                for sheet_name in wb.sheetnames:
                    if "SQL" in sheet_name:
                        continue
                    sheet = wb[sheet_name]
                    for i, row in enumerate(sheet.rows):
                        if i == 0 and sheet_name == wb.sheetnames[0]:  # Skip header row of first sheet
                            continue
                        values = [cell.value for cell in row]
                        # Ensure values match header length
                        if len(values) < len(headers):
                            values.extend([None] * (len(headers) - len(values)))
                        elif len(values) > len(headers):
                            print(f"Warning: {file_path} sheet '{sheet_name}' has {len(values)} columns, but headers expect {len(headers)}. Truncating.")
                            values = values[:len(headers)]
                        placeholders = ",".join(["?" for _ in headers])
                        cursor.execute(f"INSERT INTO {table_name} VALUES ({placeholders})", values)
                        rows_inserted += 1
                wb.close()
            except Exception as e:
                print(f"Error processing {file_path}: {e}")
    conn.commit()
    print(f"{table_name}: Inserted {rows_inserted} rows with {len(headers) if headers else 0} columns")
    return headers

# Process both folders and get headers
headers1 = process_folder(folder1_path, "table1")
headers2 = process_folder(folder2_path, "table2")

# Inspect headers and a few rows
def inspect_table(table_name, headers):
    print(f"\nInspecting {table_name}:")
    if headers is None:
        print("No headers returned - table may not have been created.")
        return
    print("Headers:", headers)
    print("Number of columns:", len(headers))
    try:
        cursor.execute(f"SELECT * FROM {table_name} LIMIT 5")
        rows = cursor.fetchall()
        if not rows:
            print("No rows found in table.")
        for i, row in enumerate(rows):
            print(f"Row {i + 1}:", row)
    except sqlite3.OperationalError as e:
        print(f"Error querying table: {e}")

inspect_table("table1", headers1)
inspect_table("table2", headers2)

# Load user IDs incrementally
try:
    wb = openpyxl.load_workbook(user_id_file, read_only=True)
    sheet = wb[wb.sheetnames[0]]
    user_ids = [row[0].value for row in sheet.rows if row[0].value]
    wb.close()
except Exception as e:
    print(f"Error reading user IDs from {user_id_file}: {e}")
    user_ids = []

# Perform LEFT JOIN and filter (only if headers exist)
if headers1 and headers2:
    query = f"""
    CREATE TABLE merged_result AS
    SELECT t1.*, t2.*
    FROM table1 t1
    LEFT JOIN table2 t2
    ON t1."key_column1" = t2."key_column2"
    WHERE t1."user_id" IN ({','.join(['?' for _ in user_ids])})
    """
    try:
        cursor.execute(query, user_ids)
        conn.commit()
        print("Join and filter completed.")
    except sqlite3.OperationalError as e:
        print(f"Error during JOIN: {e}")
        print("Check if 'key_column1', 'key_column2', and 'user_id' match the headers above.")
else:
    print("Skipping JOIN due to missing headers in one or both tables.")

# Export result to CSV if successful
try:
    cursor.execute("SELECT * FROM merged_result")
    with open("merged_filtered_result.csv", "w", encoding="utf-8") as f:
        headers = [desc[0] for desc in cursor.description]
        f.write(",".join(headers) + "\n")
        for row in cursor:
            f.write(",".join([str(val or "") for val in row]) + "\n")
    print("Result saved to 'merged_filtered_result.csv'.")
except sqlite3.OperationalError:
    print("No merged_result table to export - JOIN may have failed.")

# Clean up
conn.close()